import os, ast
from feature_selection import get_most_freq_features, monte_carlo_fs, sort_features_by_score
from model_fine_tuning import monte_carlo, store_results
from performance_measurement import measure, pr_curves, roc_curves, shap_values


def feature_selection(gpu=False):

    if not os.path.isfile("fs_result_phase1"):
        print("File of freq features not exists")
        print("Starting identification of most frequent features")
        feature_list = get_most_freq_features(gpu=gpu)
        f_out = open("fs_result_phase1", "w+")
        f_out.write("{}".format(feature_list))
        f_out.close()
    else:
        print("File of freq features exists, loading feature list...")
        feature_list = ast.literal_eval(open("fs_result_phase1", "r").read())

    if not os.path.isfile("fs_result_phase2"):
        print("No file with sorted features are found")
        feature_list = sort_features_by_score(feature_list, gpu=gpu)
        f_out = open("fs_result_phase2", "w+")
        f_out.write("{}".format(feature_list))
        f_out.close()
    else:
        print("Sorted features are loaded from file")
        feature_list = ast.literal_eval(open("fs_result_phase2", "r").read())

    if not os.path.isfile("selected_features.txt"):
        print("Start of feature measurement")
        """For purpose of simplicity and time consumption we use here iteration equal 2, 
        but in our experiment this parameter equal to 20.
        For this reason we store selected features in file and check if file already exists"""

        monte_carlo_fs(feature_list, iteration=2, gpu=gpu)
    else:
        print("Features are measured by performance.")


def fine_tuning(gpu=False):
    if not os.path.isfile("model_fine_tune_results.txt"):
        model_results = monte_carlo(models=["xgboost"], iterations=10,
                                    filename="../data/september_old_labels.csv",
                                    scale=False, gpu=gpu)
        store_results(model_results)
    else:
        print("Model is fine-tuned already")

def performance_measure(gpu=False):
    res = measure(gpu=gpu)
    pr_curves(res)
    roc_curves(res)
    model_labels = ["Statistical General only", "Statistical", "Context ", "Time", "Graph", "Our Model"]
    for i in res:
        print("{} F1:{}".format(model_labels[int(i)], sum(res[i]["F1"]) / len(res[i]["F1"])))
    print("Our model features performance of october data: F1:{} ROC-AUC:{}".format(
        sum(res["5"]["F1_october"]) / len(res["5"]["F1_october"]),
        sum(res["5"]["ROC_october"]) / len(res["5"]["ROC_october"])))
    shap_values()

if __name__ == "__main__":
    """
    Flag parameter that utilize GPU histograms in case of XGBoost model.
    Set to True only for gpu configuration and XGBoost compiled for GPU usage"""
    GPU_USE = False
    feature_selection(gpu=GPU_USE)
    fine_tuning(gpu=GPU_USE)
    performance_measure(gpu=GPU_USE)
